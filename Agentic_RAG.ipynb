{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260f69d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain_groq import ChatGroq\n",
    "from crewai_tools import SerperDevTool, ScrapeWebsiteTool\n",
    "from crewai import Agent, Task, Crew , LLM\n",
    "\n",
    "# Let's load environment variables.\n",
    "load_dotenv()\n",
    "GROQ_API_KEY = os.getenv(\"GROQ_API_KEY\")\n",
    "SERPER_API_KEY = os.getenv(\"SERPER_API_KEY\")\n",
    "\n",
    "# verification of API's\n",
    "\n",
    "if not GROQ_API_KEY or not SERPER_API_KEY :\n",
    "    raise ValueError (\"Set necessary API keys in env file.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "161da0f5",
   "metadata": {},
   "source": [
    "os - in order to access env variables and system config\n",
    "dotenv - for loading API_keys\n",
    "\n",
    "FAISS - Stores and searches embeddings in order to retrieve the most relevant text chunks\n",
    "PyPDFLoader - Read's PDF's and convert them into text\n",
    "RecursiveCharacterTextSplitter - Split long documents into smaller, chunks holding meaning\n",
    "\n",
    "HuggingFaceEmbeddings - convert text chunks into numberical embeddings (vectors)\n",
    "chatGroq - Connects langchain to Groq-hosted LLM's for faster inference.\n",
    "\n",
    "SerperDevTool - For search in internet.\n",
    "ScrapeWebsiteTool - Extract raw content from webpages.\n",
    "\n",
    "Agent - helps to define an AI role with goals,tools and behaviour\n",
    "Task - Describe a specific job an agent must complete\n",
    "Crew - Orchestrate multiple agents to work together on tasks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e797bb7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing main LLM - for routing and final answer.\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0,\n",
    "    max_tokens=500,\n",
    "    groq_api_key=GROQ_API_KEY,\n",
    "    max_retries=2,\n",
    ")\n",
    "\n",
    "#Intialize LLM for CrewAI agents\n",
    "\n",
    "crew_llm_model = LLM(\n",
    "    model=\"llama-3.3-70b-versatile\",\n",
    "    temperature=0.7,\n",
    "    max_tokens=500,\n",
    "    api_key=GROQ_API_KEY\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29d0ea92",
   "metadata": {},
   "source": [
    "We use the main LLM for routing decisions,final asnwers, and grounding on retireved context - so we keep temperature = 0\n",
    "\n",
    "so it can be - consistent,repeatable and predictable.\n",
    "\n",
    "We use crew_llm_model for search query formulation,Summarization,exploration, taking decision on how to approach a task - so we increase the temperature\n",
    "\n",
    "so it can be - flexible,mild creative, ambigue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01567217",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
